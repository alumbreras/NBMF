source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
source('~/Documents/regul.R')
category <- c(1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0)
prediction <- rev(seq_along(category))
prediction[9:10] <- mean(prediction[9:10])
seq_along(category)
seq_along(category)
category <- c(1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0)
prediction <- rev(seq_along(category))
prediction
prediction[9:10]
prediction[9:10] <- mean(prediction[9:10])
prediction
setwd("~/Documents/rNBMF/analysis")
source('~/Documents/rNBMF/analysis/xp_paper_sensitivity_analysis.R')
setwd("~/Documents/rNBMF/analysis")
source('~/Documents/rNBMF/analysis/xp_paper_sensitivity_analysis.R')
# Read all saved results from files
df <- read.table(file = results_file, sep = ",", header = T) %>% distinct()
# compute total perplexity
df <- df %>% mutate(perplexity = -loglikelihood/ntest)
# ******************************************************************************
# Plot from dataframes
# ******************************************************************************
# Perplexity (used in the paper)
base_size <- 8
p <- ggplot(df, aes(x=alpha, y=perplexity, group=alpha)) +
geom_boxplot(outlier.shape = NA) +
geom_point(colour = "red", size = 1, shape=3) +
facet_grid(size ~ ., scales = "fixed") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, size=base_size*1, hjust = 1, colour = "black"),
axis.text.y = element_text(size= base_size, color = 'black'),
strip.background =element_rect(fill="white"),
aspect.ratio = 1/3)
print(p)
ggsave(p, filename = "fig_boxplots_sensitivity_predictions_perplexity2.eps", height=18, width=13, units='cm')
# For many datasets and many algorithms
# show the dictionary of each algorithm in each dataset
# (the best, if the algorithm has to choose K)
################################################################################
devtools::load_all()
library(dplyr)
library(tidyr)
library(ggplot2)
library(Matrix)
library(gtools)
library(data.table)
library(logisticPCA)
text_components <-  7
text_features <- 7
data("animals")
V <- animals
dataset <- 'animals'
data("lastfm")
V <- lastfm
dataset <- "lastfm"
library(unvotes)
data("unvotes100coldwar_absna")
V <- unvotes100coldwar_absna
un_votes[un_votes$country == 'Federal Republic of Germany', ]$country_code <- 'FG'
un_votes[un_votes$country == 'Zanzibar', ]$country_code <- 'ZN'
un_votes[un_votes$country == 'Yemen Arab Republic', ]$country_code <- 'YR'
country_codes <- un_votes$country_code[match(rownames(V), un_votes$country)]
dataset <- 'unvotes100coldwar_absna'
data("paleo")
V <- paleo
dataset <- 'paleo'
Kmax <- 2 # set it to K in the aspect model
k = 2
logpca_model <- logisticPCA::logisticSVD(V, k, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
E_V <- fitted(logpca_model, type = "response")
V.probs <- V*E_V + (1-V)*(1-E_V)
like <- sum(log(V.probs), na.rm = TRUE)
likes[k] <- like
models[[k]] <- logpca_model
install.packages("rARPACK")
logpca_model <- logisticPCA::logisticSVD(V, k, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
E_V <- fitted(logpca_model, type = "response")
V.probs <- V*E_V + (1-V)*(1-E_V)
like <- sum(log(V.probs), na.rm = TRUE)
likes[k] <- like
models[[k]] <- logpca_model
plot_dictionary(W)
plot(W)
plot(H)
plot(t(H))
plot(H)
plot(W)
dataset
# The authors should investigate visualizing the latent space in 2D
# by restricting to two components or by applying PCA.
# The resulting scatter plots can provide further interpretable insides
# and demonstrate advantages of binary PCA.
devtools::load_all()
library(dplyr)
library(tidyr)
library(ggplot2)
library(Matrix)
library(gtools)
library(data.table)
library(logisticPCA)
data("animals")
V <- animals
dataset <- 'animals'
data("lastfm")
V <- lastfm
dataset <- "lastfm"
library(unvotes)
data("unvotes100coldwar_absna")
V <- unvotes100coldwar_absna
un_votes[un_votes$country == 'Federal Republic of Germany', ]$country_code <- 'FG'
un_votes[un_votes$country == 'Zanzibar', ]$country_code <- 'ZN'
un_votes[un_votes$country == 'Yemen Arab Republic', ]$country_code <- 'YR'
country_codes <- un_votes$country_code[match(rownames(V), un_votes$country)]
dataset <- 'unvotes100coldwar_absna'
data("paleo")
V <- paleo
dataset <- 'paleo'
data("catalanparliament")
data(catalanparliament_labels)
V <- catalanparliament
dataset <- 'parlamentcat'
data("catalanparliament")
data(catalanparliament_labels)
V <- catalanparliament
dataset <- 'parlamentcat'
modelVBDirBer <- BernoulliNMF(V, K=2, model="DirBer", method="VB",
alpha=1, beta=1, gamma=1/2,
iter=1000)
E_W <- modelVBDirBer$E_W
E_H <- modelVBDirBer$E_H
plot(E_W)
plot(E_H)
plot(E_W)
plot(E_H)
plot(W)
plot(H)
library(unvotes)
data("unvotes100coldwar_absna")
V <- unvotes100coldwar_absna
un_votes[un_votes$country == 'Federal Republic of Germany', ]$country_code <- 'FG'
un_votes[un_votes$country == 'Zanzibar', ]$country_code <- 'ZN'
un_votes[un_votes$country == 'Yemen Arab Republic', ]$country_code <- 'YR'
country_codes <- un_votes$country_code[match(rownames(V), un_votes$country)]
dataset <- 'unvotes100coldwar_absna'
data("unvotes100coldwar_absna")
V <- unvotes100coldwar_absna
modelVBDirBer <- BernoulliNMF(V, K=2, model="DirBer", method="VB",
alpha=1, beta=1, gamma=1/2,
iter=1000)
E_W <- modelVBDirBer$E_W
E_H <- modelVBDirBer$E_H
plot(E_W)
plot(E_H)
logpca_model <- logisticPCA::logisticSVD(V, k=2, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
plot(W)
plot(H)
plot(E_H)
plot(E_W)
plot(E_H)
plot(H)
H
plot(W)
par(mfrow=c(1,2))
plot(E_H)
plot(H)
par(mfrow=c(2,1))
plot(E_H)
plot(H)
dim(H)
par(mfrow=c(2,1))
plot(E_W)
plot(W)
colSums(W)
rowSums(W)
rowSums(E_W)
colSums(E_W)
dim(E_W)
dim(W)
modelVBDirBer <- BernoulliNMF(V, K=1, model="DirBer", method="VB",
alpha=1, beta=1, gamma=1/2,
iter=1000)
E_W <- modelVBDirBer$E_W
E_H <- modelVBDirBer$E_H
plot(E_W)
plot(E_H)
plot(H)
par(mfrow=c(2,1))
plot(E_H)
plot(H)
par(mfrow=c(2,1))
plot(E_W)
plot(W)
par(mfrow=c(2,1))
plot(E_H)
plot(H)
par(mfrow=c(2,1))
plot(E_W)
plot(W)
par(mfrow=c(2,1))
plot(E_H)
plot(H)
logpca_model <- logisticPCA::logisticSVD(V, k=2, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
plot(W)
plot(H)
par(mfrow=c(2,1))
plot(E_H)
plot(H)
dataset
dim(unvotes100coldwar_absna)
colnames(V)
rownames(V)
df_E_H <- as.data.frame(E_H)
df_E_H
text(E_H[,1], E_H[,2], labels=rownames(V), cex= 0.7)
E_H[,1]
E_H[1,]
E_H[,1]
dim(E_H)
dim(E_W)
V <- t(V) # I want H to represent countries-topics with Beta ranges [0,1]
dim(V)
modelVBDirBer <- BernoulliNMF(V, K=1, model="DirBer", method="VB",
alpha=1, beta=1, gamma=1/2,
iter=1000)
logpca_model <- logisticPCA::logisticSVD(V, k=2, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
names <- colnames(V)
names
W <- logpca_model$A
H <- logpca_model$B
par(mfrow=c(1,1))
plot(E_H)
text(E_H[,1], E_H[,2], labels=rownames(V), cex= 0.7)
par(mfrow=c(1,1))
plot(E_H)
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
dim(E_H)
par(mfrow=c(1,1))
plot(E_W)
dim(E_W)
text(E_W[,1], E_W[,2], labels=names, cex= 0.7)
plot(H)
text(H[,1], H[,2], labels=names, cex= 0.7)
plot(E_H)
logpca_model <- logisticPCA::logisticSVD(V, k=2, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
W <- logpca_model$A
H <- logpca_model$B
plot(H)
text(H[,1], H[,2], labels=names, cex= 0.7)
plot(W)
text(W[,1], W[,2], labels=names, cex= 0.7)
plot(E_W)
text(E_W[,1], E_W[,2], labels=names, cex= 0.7)
dim(E_W)
V <- unvotes100coldwar_absna
un_votes[un_votes$country == 'Federal Republic of Germany', ]$country_code <- 'FG'
un_votes[un_votes$country == 'Zanzibar', ]$country_code <- 'ZN'
un_votes[un_votes$country == 'Yemen Arab Republic', ]$country_code <- 'YR'
country_codes <- un_votes$country_code[match(rownames(V), un_votes$country)]
dataset <- 'unvotes100coldwar_absna'
data("unvotes100coldwar_absna")
V <- unvotes100coldwar_absna
country_codes <- un_votes$country_code[match(rownames(V), un_votes$country)]
un_votes[un_votes$country == 'Federal Republic of Germany', ]$country_code <- 'FG'
un_votes[un_votes$country == 'Zanzibar', ]$country_code <- 'ZN'
un_votes[un_votes$country == 'Yemen Arab Republic', ]$country_code <- 'YR'
country_codes <- un_votes$country_code[match(rownames(V), un_votes$country)]
un_votes[un_votes$country == 'Federal Republic of Germany', ]$country_code <- 'FG'
library(unvotes)
install.packages("unvotes")
library(unvotes)
data("unvotes100coldwar_absna")
V <- unvotes100coldwar_absna
un_votes[un_votes$country == 'Federal Republic of Germany', ]$country_code <- 'FG'
un_votes[un_votes$country == 'Zanzibar', ]$country_code <- 'ZN'
un_votes[un_votes$country == 'Yemen Arab Republic', ]$country_code <- 'YR'
country_codes <- un_votes$country_code[match(rownames(V), un_votes$country)]
dataset <- 'unvotes100coldwar_absna'
country_codes
library(unvotes)
data("unvotes100coldwar_absna")
V <- unvotes100coldwar_absna
un_votes[un_votes$country == 'Federal Republic of Germany', ]$country_code <- 'FG'
un_votes[un_votes$country == 'Zanzibar', ]$country_code <- 'ZN'
un_votes[un_votes$country == 'Yemen Arab Republic', ]$country_code <- 'YR'
country_codes <- un_votes$country_code[match(rownames(V), un_votes$country)]
dataset <- 'unvotes100coldwar_absna'
names <- country_codes
modelVBDirBer <- BernoulliNMF(V, K=1, model="DirBer", method="VB",
alpha=1, beta=1, gamma=1/2,
iter=10)
E_W <- modelVBDirBer$E_W
E_H <- modelVBDirBer$E_H
logpca_model <- logisticPCA::logisticSVD(V, k=2, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
par(mfrow=c(1,1))
plot(E_H)
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
plot(H)
text(H[,1], H[,2], labels=names, cex= 0.7)
par(mfrow=c(1,1))
plot(E_H)
par(mfrow=c(1,1))
plot(E_H)
E_W <- modelVBDirBer$E_W
E_H <- modelVBDirBer$E_H
plot(E_H)
dim(E_H)
dim(V)
V <- t(V) # I want H to represent countries-topics with Beta ranges [0,1]
modelVBDirBer <- BernoulliNMF(V, K=1, model="DirBer", method="VB",
alpha=1, beta=1, gamma=1/2,
iter=10)
E_W <- modelVBDirBer$E_W
E_H <- modelVBDirBer$E_H
plot(E_H)
par(mfrow=c(1,1))
plot(E_H)
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0)
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0)
text(H[,1], H[,2], labels=1:100, cex= 0.7)
dim(names)
length(names)
par(mfrow=c(1,1))
plot(E_H, cex= 0)
1:100
as.character(1:100)
par(mfrow=c(1,1))
plot(E_H, cex= 0)
text(H[,1], H[,2], labels=as.character(1:100), cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0)
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0)
text(H[,1], H[,2], labels=as.character(1:100), cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0)
text(E_H[,1], E_H[,2], labels=as.character(1:100), cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0)
text(E_H[,1], E_H[,2], labels=1:100, cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0)
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
plot(E_H, cex= 0)
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
plot(H, cex= 0)
text(H[,1], H[,2], labels=names, cex= 0.7)
text(H[,1], H[,2], labels=names, cex= 0.7)
dim(H)
logpca_model <- logisticPCA::logisticSVD(V, k=2, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
plot(H, cex= 0)
text(H[,1], H[,2], labels=names, cex= 0.
7)
plot(H, cex= 0)
text(H[,1], H[,2], labels=names, cex= 0.7)
plot(E_H, cex= 0)
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0, main="Beta-Dir")
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0, main="H coefficients in Beta-Dir")
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
plot(H, cex= 0, main=" coefficients in log-PCA")
text(H[,1], H[,2], labels=names, cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0, main="H coefficients in Beta-Dir")
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
plot(H, cex= 0, main="H coefficients in log-PCA")
text(H[,1], H[,2], labels=names, cex= 0.7)
par(mfrow=c(1,1))
plot(E_H, cex= 0, main="H coefficients in Beta-Dir")
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
plot(H, cex= 0, main="H coefficients in log-PCA")
text(H[,1], H[,2], labels=names, cex= 0.7)
modelVBDirBer <- BernoulliNMF(V, K=1, model="DirBer", method="VB",
alpha=1, beta=1, gamma=1/2,
iter=1000)
E_W <- modelVBDirBer$E_W
E_H <- modelVBDirBer$E_H
logpca_model <- logisticPCA::logisticSVD(V, k=2, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
par(mfrow=c(1,1))
plot(E_H, cex= 0, main="H coefficients in Beta-Dir")
text(E_H[,1], E_H[,2], labels=names, cex= 0.7)
library(unvotes)
data("unvotes100coldwar_absna")
V <- unvotes100coldwar_absna
un_votes[un_votes$country == 'Federal Republic of Germany', ]$country_code <- 'FG'
un_votes[un_votes$country == 'Zanzibar', ]$country_code <- 'ZN'
un_votes[un_votes$country == 'Yemen Arab Republic', ]$country_code <- 'YR'
country_codes <- un_votes$country_code[match(rownames(V), un_votes$country)]
dataset <- 'unvotes100coldwar_absna'
H
W
p <- plot_dictionary(W, Kmax=8, rowlabels=TRUE)
p
p <- plot_dictionary(logpca_model$A, Kmax=8, rowlabels=TRUE)
logpca_model <- logisticPCA::logisticSVD(V, k=8, max_iters = 2000)
W <- logpca_model$A
H <- logpca_model$B
p <- plot_dictionary(A_mapped, Kmax=8, rowlabels=TRUE)
A_mapped <- (logpca_model$A-min(logpca_model$A)) / (max(logpca_model$A)-min(logpca_model$A))
p <- plot_dictionary(A_mapped, Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(logpca_model$A, Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(A_mapped, Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(logpca_model$A, Kmax=8, rowlabels=TRUE)
dim(A)
dim(A_mapped)
p <- plot_dictionary(A_mapped, Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(logpca_model$A, Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(log(A_mapped), Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(A_mapped, Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(logpca_model$A, Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(log(A_mapped), Kmax=8, rowlabels=TRUE)
ogpca_model$A
logpca_model$A
log(A_mapped)
p <- plot_dictionary(log(logpca_model$A), Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(logpca_model$A, Kmax=8, rowlabels=TRUE)
A_mapped <- (logpca_model$A-min(logpca_model$A)) / (max(logpca_model$A)-min(logpca_model$A))
p <- plot_dictionary(A_mapped, Kmax=8, rowlabels=TRUE)
p <- plot_dictionary(exp(logpca_model$A), Kmax=8, rowlabels=TRUE)
source('~/Documents/rNBMF/analysis/xp_paper_sensitivity_analysis.R')
# Read all saved results from files
df <- read.table(file = results_file, sep = ",", header = T) %>% distinct()
# compute total perplexity
df <- df %>% mutate(perplexity = -loglikelihood/ntest)
# ******************************************************************************
# Plot from dataframes
# ******************************************************************************
# Perplexity (used in the paper)
base_size <- 8
p <- ggplot(df, aes(x=alpha, y=perplexity, group=alpha)) +
geom_boxplot(outlier.shape = NA) +
geom_point(colour = "red", size = 1, shape=3) +
facet_grid(size ~ ., scales = "fixed") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90, size=base_size*1, hjust = 1, colour = "black"),
axis.text.y = element_text(size= base_size, color = 'black'),
strip.background =element_rect(fill="white"),
aspect.ratio = 1/3)
print(p)
ggsave(p, filename = "fig_boxplots_sensitivity_predictions_perplexity2.eps", height=18, width=13, units='cm')
